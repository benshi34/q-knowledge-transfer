{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict\n",
    "from copy import deepcopy\n",
    "\n",
    "def load_json_file(filepath: str) -> dict:\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json_file(data: dict, filepath: str):\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "def standardize_dictionaries(leetcode_path: str, usaco_path: str):\n",
    "    # Field mappings (old_name: standard_name)\n",
    "    field_mappings = {\n",
    "        # USACO -> Standard\n",
    "        'name': 'title',                    # Standardize name to title\n",
    "        'problem_link': 'problem_link',     # Keep as is\n",
    "        'test_data_link': 'test_data_link', # Keep as is\n",
    "        'solution_link': 'solution_link',    # Keep as is\n",
    "        'contest_link': 'contest_link',      # Keep as is\n",
    "        'inner_contest_link': 'inner_contest_link', # Keep as is\n",
    "        'problem_level': 'difficulty',      # Standardize problem_level to difficulty\n",
    "        'cp_id': 'cp_id',                  # Keep as is\n",
    "        'problem_id': 'id',                # Standardize problem_id to id\n",
    "        'description': 'description',       # Keep as is\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        leetcode_dict = load_json_file(leetcode_path)\n",
    "        usaco_dict = load_json_file(usaco_path)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error loading JSON files: {e}\")\n",
    "        return\n",
    "\n",
    "    # Create new standardized dictionaries\n",
    "    new_leetcode_dict = {}\n",
    "    new_usaco_dict = {}\n",
    "\n",
    "    # Standardize LeetCode dictionary\n",
    "    for problem_id, data in leetcode_dict.items():\n",
    "        new_data = deepcopy(data)\n",
    "        new_data['source'] = 'leetcode'\n",
    "        \n",
    "        # Rename fields according to mapping\n",
    "        for old_name, new_name in field_mappings.items():\n",
    "            if old_name in new_data:\n",
    "                new_data[new_name] = new_data.pop(old_name)\n",
    "        \n",
    "        new_leetcode_dict[problem_id] = new_data\n",
    "\n",
    "    # Standardize USACO dictionary\n",
    "    for problem_id, data in usaco_dict.items():\n",
    "        new_data = deepcopy(data)\n",
    "        new_data['source'] = 'usaco'\n",
    "        \n",
    "        # Rename fields according to mapping\n",
    "        for old_name, new_name in field_mappings.items():\n",
    "            if old_name in new_data:\n",
    "                new_data[new_name] = new_data.pop(old_name)\n",
    "        \n",
    "        new_usaco_dict[problem_id] = new_data\n",
    "\n",
    "    # Save standardized dictionaries\n",
    "    save_json_file(new_leetcode_dict, leetcode_path.replace('.json', '_standardized.json'))\n",
    "    save_json_file(new_usaco_dict, usaco_path.replace('.json', '_standardized.json'))\n",
    "\n",
    "    # Print summary of changes\n",
    "    print(\"=== Standardization Summary ===\")\n",
    "    print(\"\\nStandard fields used:\")\n",
    "    for old_name, new_name in field_mappings.items():\n",
    "        if old_name != new_name:\n",
    "            print(f\"- '{old_name}' â†’ '{new_name}'\")\n",
    "    \n",
    "    print(\"\\nFiles created:\")\n",
    "    print(f\"- {leetcode_path.replace('.json', '_standardized.json')}\")\n",
    "    print(f\"- {usaco_path.replace('.json', '_standardized.json')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leetcode_path = \"leetcode_problem_dict.json\"\n",
    "usaco_path = \"usaco_subset307_dict.json\"\n",
    "standardize_dictionaries(leetcode_path, usaco_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Standardization Summary ===\n",
      "\n",
      "Fields standardized:\n",
      "- Added 'source' field with value 'livebench'\n",
      "- Created 'title' from problem ID\n",
      "- Extracted 'description' from turns\n",
      "- Created 'cp_id' from problem ID\n",
      "- Mapped competition types to difficulties\n",
      "\n",
      "File created:\n",
      "- livebench_math_question_dict_standardized.json\n"
     ]
    }
   ],
   "source": [
    "def standardize_livebench_dictionary(livebench_path: str):\n",
    "    try:\n",
    "        livebench_dict = load_json_file(livebench_path)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Create new standardized dictionary\n",
    "    new_livebench_dict = {}\n",
    "\n",
    "    # Standardize Livebench dictionary\n",
    "    for problem_id, data in livebench_dict.items():\n",
    "        new_data = {\n",
    "            'source': 'livebench',\n",
    "            'id': problem_id,\n",
    "            'title': f\"Math Question {problem_id[:8]}\",  # Use first 8 chars of hash as short ID\n",
    "            'description': data['turns'][0],  # The question text is in the first turn\n",
    "            'cp_id': problem_id[:8],         # Use first 8 chars as CP ID\n",
    "            'ground_truth': data.get('ground_truth', ''),\n",
    "            'category': data.get('category', ''),\n",
    "            'task': data.get('task', ''),\n",
    "            'subtask': data.get('subtask', '')\n",
    "        }\n",
    "        \n",
    "        # Set difficulty based on competition type\n",
    "        if 'amc' in data.get('subtask', '').lower():\n",
    "            new_data['difficulty'] = 'easy'\n",
    "        elif 'aime' in data.get('subtask', '').lower():\n",
    "            new_data['difficulty'] = 'medium'\n",
    "        elif 'imo' in data.get('subtask', '').lower():\n",
    "            new_data['difficulty'] = 'hard'\n",
    "        else:\n",
    "            new_data['difficulty'] = 'medium'  # Default to medium if unknown\n",
    "        \n",
    "        new_livebench_dict[problem_id] = new_data\n",
    "\n",
    "    # Save standardized dictionary\n",
    "    save_json_file(new_livebench_dict, livebench_path.replace('.json', '_standardized.json'))\n",
    "\n",
    "    # Print summary\n",
    "    print(\"=== Standardization Summary ===\")\n",
    "    print(\"\\nFields standardized:\")\n",
    "    print(\"- Added 'source' field with value 'livebench'\")\n",
    "    print(\"- Created 'title' from problem ID\")\n",
    "    print(\"- Extracted 'description' from turns\")\n",
    "    print(\"- Created 'cp_id' from problem ID\")\n",
    "    print(\"- Mapped competition types to difficulties\")\n",
    "    \n",
    "    print(\"\\nFile created:\")\n",
    "    print(f\"- {livebench_path.replace('.json', '_standardized.json')}\")\n",
    "\n",
    "# Usage\n",
    "livebench_path = \"livebench_math_question_dict.json\"\n",
    "standardize_livebench_dictionary(livebench_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
